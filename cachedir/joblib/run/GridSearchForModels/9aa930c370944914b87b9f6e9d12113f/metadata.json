{"duration": 158.92655205726624, "input_args": {"XData": "     sepal_l  sepal_w  petal_l  petal_w\n0        6.3      3.3      6.0      2.5\n1        7.1      3.0      5.9      2.1\n2        5.8      2.7      5.1      1.9\n3        6.3      2.9      5.6      1.8\n4        7.6      3.0      6.6      2.1\n..       ...      ...      ...      ...\n145      5.1      3.8      1.6      0.2\n146      5.0      3.5      1.6      0.6\n147      5.1      3.4      1.5      0.2\n148      4.6      3.2      1.4      0.2\n149      4.8      3.0      1.4      0.3\n\n[150 rows x 4 columns]", "yData": "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]", "clf": "MLPClassifier(activation='tanh', alpha=0.00081, batch_size='auto', beta_1=0.9,\n              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n              hidden_layer_sizes=(100,), learning_rate='constant',\n              learning_rate_init=0.001, max_fun=15000, max_iter=100,\n              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n              power_t=0.5, random_state=None, shuffle=True, solver='sgd',\n              tol=0.00081, validation_fraction=0.1, verbose=False,\n              warm_start=False)", "params": "{'alpha': [1e-05, 0.00021, 0.00041000000000000005, 0.0006100000000000001, 0.0008100000000000001], 'tol': [1e-05, 0.00041000000000000005, 0.0008100000000000001], 'max_iter': [100], 'activation': ['relu', 'identity', 'logistic', 'tanh'], 'solver': ['adam', 'sgd']}", "eachAlgor": "'MLP'", "AlgorithmsIDsEnd": "1236"}}